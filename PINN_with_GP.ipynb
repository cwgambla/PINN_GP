{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ed5b982-8c24-4e7d-82a6-40d126faa105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e2ed6c4-6360-48f1-94cc-5b66d11d8d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.4823296070098877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss: 0.0015051770024001598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss: 0.0003130151890218258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500, Loss: 0.0005794610478915274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000, Loss: 7.327131606871262e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2500, Loss: 3.7335583328967914e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000, Loss: 2.939054866146762e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3500, Loss: 2.114432936650701e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000, Loss: 1.967523894563783e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4500, Loss: 8.391240407945588e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000, Loss: 0.00012017238623229787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5500, Loss: 1.848136162152514e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6000, Loss: 7.292946975212544e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6500, Loss: 1.7554588339407928e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000, Loss: 0.0001875834132079035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7500, Loss: 5.254019015410449e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8000, Loss: 2.8065887818229385e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8500, Loss: 2.4066407604550477e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:660: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL: .\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9000, Loss: 0.002515241736546159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:478: UserWarning: Predicted variances smaller than 0. Setting those variances to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9500, Loss: 0.0002165181649615988\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Berger Viscous Equation parameters\n",
    "c = 1.0    # Wave speed\n",
    "mu = 0.1   # Viscosity coefficient\n",
    "lam = 1.0  # Nonlinearity coefficient\n",
    "\n",
    "# Define the neural network\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.net = nn.Sequential(*[\n",
    "            nn.Sequential(nn.Linear(layers[i], layers[i+1]), nn.Tanh())\n",
    "            for i in range(len(layers)-2)\n",
    "        ] + [nn.Linear(layers[-2], layers[-1])])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        inputs = torch.cat((x, t), dim=1)\n",
    "        return self.net(inputs)\n",
    "\n",
    "# Compute PDE residual using automatic differentiation\n",
    "def compute_pde_residual(model, x, t):\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    t = t.clone().detach().requires_grad_(True)\n",
    "\n",
    "    u = model(x, t)  # Predict u(x, t)\n",
    "    \n",
    "    u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    u_tt = torch.autograd.grad(u_t, t, torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    \n",
    "    u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    f = u_tt - c**2 * u_xx - mu * u_xx + lam * u * u_xx  # PDE residual\n",
    "    return f\n",
    "\n",
    "# Importance sampling: Generate collocation points based on residuals\n",
    "def generate_collocation_points(model, N_f, L=1.0, T=1.0):\n",
    "    x_f = torch.rand(N_f, 1, device=device, requires_grad=True) * L  # x in [0, L]\n",
    "    t_f = torch.rand(N_f, 1, device=device, requires_grad=True) * T  # t in [0, T]\n",
    "    \n",
    "    if model is not None:  # Perform importance sampling\n",
    "        residuals = compute_pde_residual(model, x_f, t_f).detach()\n",
    "        probabilities = residuals.abs() / torch.sum(residuals.abs())  # Normalize to form a probability distribution\n",
    "        sampled_indices = torch.multinomial(probabilities.view(-1), N_f, replacement=True)\n",
    "        x_f, t_f = x_f[sampled_indices], t_f[sampled_indices]\n",
    "    \n",
    "    return x_f, t_f\n",
    "\n",
    "def fit_GP(x,t):\n",
    "    kernel = C(1.0) * RBF(length_scale=1.0)\n",
    "\n",
    "# Create the Gaussian Process Regressor\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)\n",
    "    x_0 = x.cpu().detach().numpy() \n",
    "    t_0 = t.cpu().detach().numpy()\n",
    "    gp.fit(x_0,t_0)\n",
    "    y_pred, sigma = gp.predict(x_0, return_std=True)\n",
    "    \n",
    "    most_uncertain_indices = np.argsort(-sigma)[:100]  # Sort in descending order and take top 100\n",
    "    most_uncertain_points = x_0[most_uncertain_indices]\n",
    "\n",
    "    most_uncertain_indices = torch.tensor(most_uncertain_points,device=device, requires_grad=True)\n",
    "    most_uncertain_points=torch.tensor(most_uncertain_points, device=device, requires_grad=True)\n",
    "    return most_uncertain_points,most_uncertain_indices\n",
    "    \n",
    "# Define loss function\n",
    "def loss_function(model, x_f, t_f, x_bc, t_bc, u_bc):\n",
    "    f_residual = compute_pde_residual(model, x_f, t_f)\n",
    "    loss_pde = torch.mean(f_residual**2)\n",
    "\n",
    "    u_pred_bc = model(x_bc, t_bc)\n",
    "    loss_bc = torch.mean((u_pred_bc - u_bc)**2)\n",
    "\n",
    "    return loss_pde + loss_bc\n",
    "\n",
    "# Training loop with dynamic importance sampling\n",
    "def train(model, optimizer, N_f, x_bc, t_bc, u_bc, epochs=5000, resample_every=500):\n",
    "    x_f, t_f = generate_collocation_points(model, N_f)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "           \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(model, x_f, t_f, x_bc, t_bc, u_bc)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            # x_f,t_f = fit_GP(x_f,t_f)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            x_uncertain, t_uncertain = fit_GP(x_f, t_f) \n",
    "            x_f_new, t_f_new = generate_collocation_points(model, N_f)  # Generate 1000 new points\n",
    "            x_f = torch.cat([x_f_new, x_uncertain], dim=0)\n",
    "            t_f = torch.cat([t_f_new, t_uncertain], dim=0)\n",
    "\n",
    "# Define PINN model architecture\n",
    "layers = [2, 50, 50, 50, 1]  # Input (x,t) -> Hidden layers -> Output (u)\n",
    "model = PINN(layers).to(device)\n",
    "\n",
    "# Define boundary and initial conditions\n",
    "N_f = 1000  # Collocation points\n",
    "L, T = 1.0, 1.0  # Spatial and time limits\n",
    "\n",
    "x_f, t_f = generate_collocation_points(None, N_f, L, T)  # Initial uniform sampling\n",
    "\n",
    "# Boundary conditions (u(x, 0) = sin(pi x), u(0, t) = 0, u(L, t) = 0)\n",
    "N_bc = 100\n",
    "x_bc = torch.linspace(0, L, N_bc).view(-1, 1).to(device)\n",
    "t_bc = torch.zeros_like(x_bc).to(device)\n",
    "u_bc = torch.sin(np.pi * x_bc.cpu()).to(device)  # Initial condition\n",
    "\n",
    "# Train the model with importance sampling\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "train(model, optimizer, N_f, x_bc, t_bc, u_bc, epochs=10000, resample_every=100)\n",
    "\n",
    "# Visualize results\n",
    "x_test = torch.linspace(0, L, 100).view(-1, 1).to(device)\n",
    "t_test = torch.linspace(0, T, 100).view(-1, 1).to(device)\n",
    "\n",
    "x_grid, t_grid = torch.meshgrid(x_test.squeeze(), t_test.squeeze(), indexing='ij')\n",
    "x_flat, t_flat = x_grid.flatten().view(-1, 1), t_grid.flatten().view(-1, 1)\n",
    "\n",
    "u_pred = model(x_flat, t_flat).detach().cpu().numpy().reshape(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b907c5c-d2b4-481f-a771-7cf1aa925e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.146892547607422"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loss on general function\n",
    "x_f, t_f = generate_collocation_points(model, 1000,L,T)\n",
    "x_bc = torch.linspace(0, L, N_bc).view(-1, 1).to(device)\n",
    "t_bc = torch.zeros_like(x_bc).to(device)\n",
    "u_bc = torch.sin(np.pi * x_bc.cpu()).to(device)\n",
    "\n",
    "loss_function(model, x_f, t_f, x_bc, t_bc, u_bc).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b58d5b-f065-4e15-8683-4e26d0d682b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
