{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7453f0b-5742-46dc-8610-822e29560a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.stats import qmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c84606-90c8-456e-8fc8-630849cfe972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the Berger Viscous Equation parameters\n",
    "c = 1.0    # Wave speed\n",
    "mu = 0.1   # Viscosity coefficient\n",
    "lam = 1.0  # Nonlinearity coefficient\n",
    "\n",
    "# Define the neural network\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.net = nn.Sequential(*[\n",
    "            nn.Sequential(nn.Linear(layers[i], layers[i+1]), nn.Tanh())\n",
    "            for i in range(len(layers)-2)\n",
    "        ] + [nn.Linear(layers[-2], layers[-1])])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        inputs = torch.cat((x, t), dim=1)\n",
    "        return self.net(inputs)\n",
    "\n",
    "def generate_collocation_points(N_f, L=1.0, T=1.0):\n",
    "    # Use Latin Hypercube Sampling for better distribution\n",
    "    sampler = qmc.LatinHypercube(d=2)  # 2D (x, t) space\n",
    "    sample = sampler.random(N_f)  # Generate N_f samples in [0, 1]^2\n",
    "\n",
    "    # Scale samples: x in [-L, L], t in [0, T]\n",
    "    x_f = torch.tensor((sample[:, 0] * 2 - 1) * L, dtype=torch.float32).reshape(-1, 1)\n",
    "    t_f = torch.tensor(sample[:, 1] * T, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    return x_f.to(device), t_f.to(device)\n",
    "def compute_pde_residual(model, x, t):\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    t = t.clone().detach().requires_grad_(True)\n",
    "\n",
    "    u = model(x, t)  # Predict u(x, t)\n",
    "\n",
    "    u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0]\n",
    "    u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]\n",
    "\n",
    "    # Inviscid Burgers' equation: u_t + u * u_x = 0\n",
    "    f = u_t + u * u_x\n",
    "    return f\n",
    "\n",
    "\n",
    "# Define loss function\n",
    "def loss_function(model, x_f, t_f, x_bc, t_bc, u_bc):\n",
    "    f_residual = compute_pde_residual(model, x_f, t_f)\n",
    "    loss_pde = torch.mean(f_residual**2)\n",
    "\n",
    "    u_pred_bc = model(x_bc, t_bc)\n",
    "    loss_bc = torch.mean((u_pred_bc - u_bc)**2)\n",
    "\n",
    "    return loss_pde + loss_bc\n",
    "\n",
    "def val_loss(model, x_f, t_f, x_bc, t_bc, u_bc):\n",
    "    f_residual = compute_pde_residual(model, x_f, t_f)\n",
    "    loss_pde = torch.mean(f_residual**2)\n",
    "\n",
    "    u_pred_bc = model(x_bc, t_bc)\n",
    "    loss_bc = torch.mean((u_pred_bc - u_bc)**2)\n",
    "\n",
    "    return loss_pde + loss_bc\n",
    "    # return loss_pde\n",
    "\n",
    "# Training loop\n",
    "def train(model, optimizer, N_f, x_f, t_f, valX, valT, x_bc, t_bc, u_bc, epochs=5000,threshold = 0.001):\n",
    "    val_scores = []\n",
    "    thresh_e = epochs\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(model, x_f, t_f, x_bc, t_bc, u_bc)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = val_loss(model, valX, valT, x_bc, t_bc, u_bc)\n",
    "\n",
    "        if loss_val.item() < threshold and thresh_e >= epochs:\n",
    "            print(\"Threshold reach at:\",epoch)\n",
    "            print(\"Val loss:\",loss_val)\n",
    "            thresh_e = epoch\n",
    "\n",
    "        if epoch % 500 == 0 or epoch == epochs-1:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            val_scores.append(loss_val.item())\n",
    "        x_f,t_f = generate_collocation_points(N_f)\n",
    "\n",
    "    return thresh_e, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33a584c-da77-4226-b52c-421a2b76152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_points_import(model, N_f, L=1.0, T=1.0):\n",
    "    x_f = (torch.rand(N_f, 1, device=device, requires_grad=True) * 2 - 1) * L  # x in [-L, L]\n",
    "    t_f = torch.rand(N_f, 1, device=device, requires_grad=True) * T  # t in [0, T]\n",
    "    \n",
    "    if model is not None:  # Perform importance sampling\n",
    "        residuals = compute_pde_residual(model, x_f, t_f).detach()\n",
    "        probabilities = residuals.abs() / torch.sum(residuals.abs())\n",
    "        sampled_indices = torch.multinomial(probabilities.view(-1), N_f, replacement=True)\n",
    "        x_f, t_f = x_f[sampled_indices], t_f[sampled_indices]\n",
    "    \n",
    "    return x_f, t_f\n",
    "\n",
    "def train_import(model, optimizer, N_f, x_f,t_f,valX ,valT ,x_bc, t_bc, u_bc, epochs=10000, resample_every=5000,threshold = 0.001):\n",
    "\n",
    "    val_scores = []\n",
    "    thresh_e = epochs\n",
    "    for epoch in range(epochs):\n",
    "        # if epoch % resample_every == 0 and epoch >=500:\n",
    "        #     x_f, t_f = gen_points_import(model, N_f)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(model, x_f, t_f, x_bc, t_bc, u_bc)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = val_loss(model, valX, valT, x_bc, t_bc, u_bc)\n",
    "\n",
    "        if loss_val.item() < threshold and thresh_e >= epochs:\n",
    "            print(\"Threshold reach at:\",epoch)\n",
    "            print(\"Val loss:\",loss_val)\n",
    "            thresh_e = epoch\n",
    "        if epoch % 500 == 0 or epoch == epochs-1:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            val_scores.append(loss_val.item())\n",
    "        x_f, t_f = gen_points_import(model, N_f)\n",
    "    return thresh_e, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70cbf4b8-6868-49b9-a497-baf121411e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Process Model for Importance Sampling\n",
    "class ResidualGP(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ResidualGP, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "    gpytorch.kernels.MaternKernel(nu=1.5)\n",
    ")\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add3657c-f43b-450f-8b99-787968a28023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def generate_collocation_points_with_gp(model, N_f, x_f, t_f, x_bc=None, t_bc=None, u_bc=None, \n",
    "                                        L=1.0, T=1.0, alpha=0.5, fraction_gp=0.5, residual_thresh=1e-3):\n",
    "    device = x_f.device\n",
    "\n",
    "    # === Step 1: Prepare GP training data ===\n",
    "    x_f,t_f = generate_collocation_points(N_f)\n",
    "    x_train = x_f\n",
    "    t_train = t_f\n",
    "    xt_train = torch.cat([x_train, t_train], dim=1).detach()\n",
    "\n",
    "    if model is not None:\n",
    "        with torch.no_grad():\n",
    "            u_train = model(x_train, t_train).detach().view(-1)\n",
    "            xt_all = xt_train\n",
    "            u_all = u_train\n",
    "\n",
    "            if x_bc is not None and t_bc is not None and u_bc is not None:\n",
    "                xt_bc = torch.cat([x_bc, t_bc], dim=1).detach()\n",
    "                u_bc = u_bc.detach().view(-1)\n",
    "                xt_all = torch.cat([xt_all, xt_bc], dim=0)\n",
    "                u_all = torch.cat([u_all, u_bc], dim=0)\n",
    "\n",
    "        # === Train GP ===\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        gp_model = ResidualGP(xt_all, u_all, likelihood).to(device)\n",
    "\n",
    "        gp_model.train()\n",
    "        likelihood.train()\n",
    "        optimizer = torch.optim.Adam(gp_model.parameters(), lr=0.01)\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, gp_model)\n",
    "\n",
    "        for _ in range(100):\n",
    "            optimizer.zero_grad()\n",
    "            output = gp_model(xt_all)\n",
    "            loss = -mll(output, u_all)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        gp_model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        # === Step 2: Generate candidate points ===\n",
    "        sampler = qmc.LatinHypercube(d=2)\n",
    "        sample = sampler.random(10 * N_f)\n",
    "        x_cand = torch.tensor(sample[:, 0] * L, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "        t_cand = torch.tensor(sample[:, 1] * T, dtype=torch.float32).reshape(-1, 1).to(device)\n",
    "        xt_cand = torch.cat([x_cand, t_cand], dim=1)\n",
    "\n",
    "        # === Step 3: Sample from GP posterior ===\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            dist = gp_model(xt_cand)\n",
    "            gp_samples = dist.rsample(torch.Size([1])) # shape: [1, N_cand]\n",
    "            gp_sample_abs = gp_samples.squeeze(0).abs().detach()  # [N_cand]\n",
    "\n",
    "        # === Step 4: Compute PDE residuals ===\n",
    "        x_cand.requires_grad_()\n",
    "        t_cand.requires_grad_()\n",
    "        residual = compute_pde_residual(model, x_cand, t_cand).detach().abs().view(-1)\n",
    "\n",
    "        # === Step 5: Normalize and combine scores ===\n",
    "        residual = torch.where(residual < residual_thresh, torch.tensor(0.0, device=device), residual)\n",
    "\n",
    "        sample_score = gp_sample_abs / (gp_sample_abs.sum() + 1e-8)\n",
    "        residual_score = residual / (residual.sum() + 1e-8)\n",
    "\n",
    "        sampling_score = alpha * sample_score + (1 - alpha) * residual_score\n",
    "        sampling_score = sampling_score / (sampling_score.sum() + 1e-8)\n",
    "\n",
    "        # === Step 6: Hybrid sampling ===\n",
    "        N_gp = int(fraction_gp * N_f)\n",
    "        N_rand = N_f - N_gp\n",
    "\n",
    "        sampled_indices_gp = torch.multinomial(sampling_score, N_gp, replacement=False)\n",
    "        sampled_indices_rand = torch.randint(0, len(x_cand), (N_rand,), device=device)\n",
    "        sampled_indices = torch.cat([sampled_indices_gp, sampled_indices_rand], dim=0)\n",
    "\n",
    "        x_f_new = x_cand[sampled_indices].detach().clone().requires_grad_()\n",
    "        t_f_new = t_cand[sampled_indices].detach().clone().requires_grad_()\n",
    "        uncertainty_top = gp_sample_abs[sampled_indices].detach().cpu()\n",
    "\n",
    "    else:\n",
    "        x_f_new = x_f.clone().detach().requires_grad_()\n",
    "        t_f_new = t_f.clone().detach().requires_grad_()\n",
    "        uncertainty_top = None\n",
    "        gp_model = None\n",
    "\n",
    "    return x_f_new, t_f_new, uncertainty_top, gp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74846ed7-0cc6-4e51-8420-9f4b6f4528ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GP(model, optimizer, N_f, x_f,t_f,valX, valT,x_bc, t_bc, u_bc, epochs=5000, resample_every=500,threshold = 0.001):\n",
    "    thresh_e = epochs\n",
    "    val_scores = []\n",
    "    for epoch in range(epochs):\n",
    "        # if epoch % resample_every == 0 and epoch >=500:\n",
    "        #     x_f, t_f = gen_points_import(model, N_f)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(model, x_f, t_f, x_bc, t_bc, u_bc)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = val_loss(model, valX, valT, x_bc, t_bc, u_bc)\n",
    "\n",
    "        if loss_val.item() < threshold and thresh_e >= epochs:\n",
    "            print(\"Threshold reach at:\",epoch)\n",
    "            print(\"Val loss:\",loss_val)\n",
    "            thresh_e = epoch\n",
    "\n",
    "        if epoch % 500 == 0 or epoch == epochs-1:\n",
    "            # x_f,t_f = fit_GP(x_f,t_f)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            val_scores.append(loss_val.item())\n",
    "            # x_uncertain, t_uncertain,x,g = generate_collocation_points_with_gp(model,N_f,x_f, t_f) \n",
    "        if epoch % resample_every == 0 and epoch > 0 :\n",
    "            x_f, t_f = gen_points_import(model, N_f)\n",
    "            x_uncertain, t_uncertain,uncertainties,gp_model = generate_collocation_points_with_gp(model,N_f,x_f, t_f,x_bc,t_bc,u_bc)\n",
    "\n",
    "            x_f = x_uncertain\n",
    "            t_f = t_uncertain\n",
    "\n",
    "    return thresh_e, val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14839f28-396b-4d33-9437-6a0e444c1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from scipy.stats import qmc\n",
    "\n",
    "def generate_collocation_points_with_gp_res(model, N_f, x_f, t_f, x_bc=None, t_bc=None, u_bc=None, \n",
    "                                            L=2.0, T=1.0, alpha=0.5, fraction_gp=0.5, residual_thresh=1e-3):\n",
    "\n",
    "    device = x_f.device\n",
    "    x_f,t_f = generate_collocation_points(N_f)\n",
    "    x_train = x_f\n",
    "    t_train = t_f\n",
    "    xt_train = torch.cat([x_train, t_train], dim=1).detach()\n",
    "\n",
    "    if model is not None:\n",
    "        # ✅ Compute residuals (no torch.no_grad here)\n",
    "        residual_train = compute_pde_residual(model, x_train.requires_grad_(), t_train.requires_grad_()).detach().view(-1)\n",
    "\n",
    "        xt_all = xt_train\n",
    "        residual_all = residual_train\n",
    "\n",
    "        if x_bc is not None and t_bc is not None and u_bc is not None:\n",
    "            xt_bc = torch.cat([x_bc, t_bc], dim=1).detach()\n",
    "            residual_bc = compute_pde_residual(model, x_bc.requires_grad_(), t_bc.requires_grad_()).detach().view(-1)\n",
    "\n",
    "            xt_all = torch.cat([xt_all, xt_bc], dim=0)\n",
    "            residual_all = torch.cat([residual_all, residual_bc], dim=0)\n",
    "\n",
    "        # === Train GP on residuals ===\n",
    "        likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "        gp_model = ResidualGP(xt_all, residual_all, likelihood).to(device)\n",
    "\n",
    "        gp_model.train()\n",
    "        likelihood.train()\n",
    "        optimizer = torch.optim.Adam(gp_model.parameters(), lr=0.01)\n",
    "        mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, gp_model)\n",
    "\n",
    "        for _ in range(100):\n",
    "            optimizer.zero_grad()\n",
    "            output = gp_model(xt_all)\n",
    "            loss = -mll(output, residual_all)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        gp_model.eval()\n",
    "        likelihood.eval()\n",
    "\n",
    "        # === Step 2: Candidate points ===\n",
    "        sampler = qmc.LatinHypercube(d=2)\n",
    "        sample = sampler.random(10 * N_f)\n",
    "\n",
    "        # x ∈ [-L/2, L/2], t ∈ [0, T]\n",
    "        x_cand = torch.tensor((sample[:, 0] * 2 - 1) * (L/2), dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "        t_cand = torch.tensor(sample[:, 1] * T, dtype=torch.float32, device=device).reshape(-1, 1)\n",
    "        xt_cand = torch.cat([x_cand, t_cand], dim=1)\n",
    "\n",
    "        # === Step 3 (Modified): Sample from GP posterior ===\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            dist = gp_model(xt_cand)\n",
    "            gp_samples = dist.rsample(torch.Size([1]))  # [1, N_cand]\n",
    "            gp_sample_abs = gp_samples.squeeze(0).abs().detach()  # [N_cand]\n",
    "  # [N_cand]\n",
    "\n",
    "        # === Step 4: Compute PDE residuals at candidate points\n",
    "        x_cand.requires_grad_()\n",
    "        t_cand.requires_grad_()\n",
    "        residual = compute_pde_residual(model, x_cand, t_cand).detach().abs().view(-1)\n",
    "\n",
    "        # === Step 5: Normalize and threshold ===\n",
    "        residual = torch.where(residual < residual_thresh, torch.tensor(0.0, device=device), residual)\n",
    "\n",
    "        sample_score = gp_sample_abs / (gp_sample_abs.sum() + 1e-8)\n",
    "        residual_score = residual / (residual.sum() + 1e-8)\n",
    "\n",
    "        sampling_score = alpha * sample_score + (1 - alpha) * residual_score\n",
    "        sampling_score = sampling_score / (sampling_score.sum() + 1e-8)\n",
    "\n",
    "        # === Step 6: Hybrid sampling ===\n",
    "        N_gp = int(fraction_gp * N_f)\n",
    "        N_rand = N_f - N_gp\n",
    "\n",
    "        sampled_indices_gp = torch.multinomial(sampling_score, N_gp, replacement=False)\n",
    "        sampled_indices_rand = torch.randint(0, len(x_cand), (N_rand,), device=device)\n",
    "        sampled_indices = torch.cat([sampled_indices_gp, sampled_indices_rand], dim=0)\n",
    "\n",
    "        x_f_new = x_cand[sampled_indices].detach().clone().requires_grad_()\n",
    "        t_f_new = t_cand[sampled_indices].detach().clone().requires_grad_()\n",
    "        uncertainty_top = gp_sample_abs[sampled_indices].detach().cpu()\n",
    "\n",
    "    else:\n",
    "        x_f_new = x_f.clone().detach().requires_grad_()\n",
    "        t_f_new = t_f.clone().detach().requires_grad_()\n",
    "        uncertainty_top = None\n",
    "        gp_model = None\n",
    "\n",
    "    return x_f_new, t_f_new, uncertainty_top, gp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23edc311-f498-4429-8f30-5f8ca7d6bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GP_res(model, optimizer, N_f, x_f,t_f,valX, valT,x_bc, t_bc, u_bc, epochs=5000, resample_every=500,threshold = 0.001):\n",
    "    val_scores = []\n",
    "    thresh_e = epochs\n",
    "    for epoch in range(epochs):\n",
    "        # if epoch % resample_every == 0 and epoch >=500:\n",
    "        #     x_f, t_f = gen_points_import(model, N_f)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(model, x_f, t_f, x_bc, t_bc, u_bc)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = val_loss(model, valX, valT, x_bc, t_bc, u_bc)\n",
    "\n",
    "        if loss_val.item() < threshold and thresh_e >= epochs:\n",
    "            print(\"Threshold reach at:\",epoch)\n",
    "            print(\"Val loss:\",loss_val)\n",
    "            thresh_e = epoch\n",
    "\n",
    "        if epoch % 500 == 0 or epoch == epochs-1:\n",
    "            # x_f,t_f = fit_GP(x_f,t_f)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            val_scores.append(loss_val.item())\n",
    "            # x_uncertain, t_uncertain,x,g = generate_collocation_points_with_gp(model,N_f,x_f, t_f) \n",
    "        if epoch % resample_every == 0 and epoch > 0 :\n",
    "            x_f, t_f = gen_points_import(model, N_f)\n",
    "            x_uncertain, t_uncertain,uncertainties,gp_model = generate_collocation_points_with_gp_res(model,N_f,x_f, t_f,x_bc,t_bc,u_bc)\n",
    "\n",
    "            x_f = x_uncertain\n",
    "            t_f = t_uncertain\n",
    "\n",
    "    return thresh_e,val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77df1d39-a260-4847-938a-517b4790062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "layers = [2, 50, 50, 50, 1]\n",
    "N_f = 1000\n",
    "L, T = 1.0, 1.0\n",
    "N_bc = 100\n",
    "epochs = 10000\n",
    "threshold = 0.05\n",
    "\n",
    "x_f, t_f = generate_collocation_points(N_f, L, T)\n",
    "x_val, t_val = generate_collocation_points(10000, L, T)\n",
    "\n",
    "x_bc = torch.linspace(0, L, N_bc).view(-1, 1).to(device)\n",
    "t_bc = torch.zeros_like(x_bc).to(device)\n",
    "u_bc = (torch.sin(np.pi * x_bc.cpu())).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aac06e3-43f1-44bf-b7bc-04a4136d9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=0.5\n",
    "sigma=0.1\n",
    "u_bc = torch.exp(-((x_bc - mu)**2) / (2 * sigma**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e379770e-7dcc-4497-8345-aca2404764a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cadmin/anaconda3/envs/Data_Science_V2/lib/python3.11/site-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.11470962315797806\n",
      "Threshold reach at: 92\n",
      "Val loss: tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch 500, Loss: 0.021093502640724182\n",
      "Epoch 1000, Loss: 0.020937366411089897\n",
      "Epoch 1500, Loss: 0.019837699830532074\n",
      "Epoch 2000, Loss: 0.019609913229942322\n",
      "Epoch 2500, Loss: 0.020116576924920082\n",
      "Epoch 3000, Loss: 0.02034420147538185\n",
      "Epoch 3500, Loss: 0.01781993731856346\n",
      "Epoch 4000, Loss: 0.019097521901130676\n",
      "Epoch 4500, Loss: 0.01739583909511566\n",
      "Epoch 5000, Loss: 0.018074635416269302\n",
      "Epoch 5500, Loss: 0.01791514828801155\n",
      "Epoch 6000, Loss: 0.017718655988574028\n",
      "Epoch 6500, Loss: 0.01723519340157509\n",
      "Epoch 7000, Loss: 0.016528645530343056\n",
      "Epoch 7500, Loss: 0.01579640433192253\n",
      "Epoch 8000, Loss: 0.01527395285665989\n",
      "Epoch 8500, Loss: 0.016506170853972435\n",
      "Epoch 9000, Loss: 0.01901760697364807\n",
      "Epoch 9500, Loss: 0.016279201954603195\n",
      "Epoch 9999, Loss: 0.01582588627934456\n",
      "0.016387758776545525\n"
     ]
    }
   ],
   "source": [
    "model_base = PINN(layers).to(device)\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=1e-3)\n",
    "thresh_base, base_scores = train(model_base, optimizer, N_f,x_f, t_f, x_val, t_val, x_bc, t_bc, u_bc, epochs=epochs, threshold=threshold)\n",
    "print(val_loss(model_base, x_val, t_val, x_bc, t_bc, u_bc).item())\n",
    "del model_base, optimizer\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a87a4c28-7da6-4acd-a9c5-486259ecc2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.16875721514225006\n",
      "Threshold reach at: 150\n",
      "Val loss: tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch 500, Loss: 0.04071260988712311\n",
      "Epoch 1000, Loss: 0.035373564809560776\n",
      "Epoch 1500, Loss: 0.03265974298119545\n",
      "Epoch 2000, Loss: 0.03326742351055145\n",
      "Epoch 2500, Loss: 0.03139621019363403\n",
      "Epoch 3000, Loss: 0.03404255583882332\n",
      "Epoch 3500, Loss: 0.031780146062374115\n",
      "Epoch 4000, Loss: 0.0279547069221735\n",
      "Epoch 4500, Loss: 0.02830931916832924\n",
      "Epoch 5000, Loss: 0.027822477743029594\n",
      "Epoch 5500, Loss: 0.028684401884675026\n",
      "Epoch 6000, Loss: 0.027531301602721214\n",
      "Epoch 6500, Loss: 0.027836201712489128\n",
      "Epoch 7000, Loss: 0.02645731158554554\n",
      "Epoch 7500, Loss: 0.027023794129490852\n",
      "Epoch 8000, Loss: 0.027157871052622795\n",
      "Epoch 8500, Loss: 0.027079543098807335\n",
      "Epoch 9000, Loss: 0.026991156861186028\n",
      "Epoch 9500, Loss: 0.026987481862306595\n",
      "Epoch 9999, Loss: 0.029442274942994118\n",
      "0.025125794112682343\n"
     ]
    }
   ],
   "source": [
    "model_import = PINN(layers).to(device)\n",
    "optimizer = optim.Adam(model_import.parameters(), lr=1e-3)\n",
    "thresh_base, base_scores = train_import(model_import, optimizer, N_f,x_f, t_f, x_val, t_val, x_bc, t_bc, u_bc, epochs=epochs, threshold=threshold)\n",
    "print(val_loss(model_import, x_val, t_val, x_bc, t_bc, u_bc).item())\n",
    "del model_import, optimizer\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95b84d1-a6fc-41bf-8e7f-bc69f9c206b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.23078027367591858\n",
      "Threshold reach at: 151\n",
      "Val loss: tensor(0.0496, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch 500, Loss: 0.021260682493448257\n",
      "Epoch 1000, Loss: 0.030962366610765457\n",
      "Epoch 1500, Loss: 0.026342371478676796\n",
      "Epoch 2000, Loss: 0.025003455579280853\n",
      "Epoch 2500, Loss: 0.023973941802978516\n",
      "Epoch 3000, Loss: 0.022236516699194908\n",
      "Epoch 3500, Loss: 0.02167249470949173\n",
      "Epoch 4000, Loss: 0.02184399589896202\n",
      "Epoch 4500, Loss: 0.02687235176563263\n",
      "Epoch 5000, Loss: 0.02379562333226204\n",
      "Epoch 5500, Loss: 0.024253811687231064\n",
      "Epoch 6000, Loss: 0.020763922482728958\n",
      "Epoch 6500, Loss: 0.027031492441892624\n",
      "Epoch 7000, Loss: 0.026477593928575516\n",
      "Epoch 7500, Loss: 0.025368155911564827\n",
      "Epoch 8000, Loss: 0.02346876449882984\n",
      "Epoch 8500, Loss: 0.023770647123456\n",
      "Epoch 9000, Loss: 0.020306173712015152\n",
      "Epoch 9500, Loss: 0.027564503252506256\n",
      "Epoch 9999, Loss: 0.024410706013441086\n",
      "0.021776534616947174\n"
     ]
    }
   ],
   "source": [
    "model_Gauss = PINN(layers).to(device)\n",
    "optimizer = optim.Adam(model_Gauss.parameters(), lr=1e-3)\n",
    "thresh_base, base_scores = train_GP(model_Gauss, optimizer, N_f,x_f, t_f, x_val, t_val, x_bc, t_bc, u_bc, epochs=epochs, threshold=threshold)\n",
    "print(val_loss(model_Gauss, x_val, t_val, x_bc, t_bc, u_bc).item())\n",
    "del model_Gauss, optimizer\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f32ed43-c049-429b-9a2a-a84944783353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2302505522966385\n",
      "Threshold reach at: 185\n",
      "Val loss: tensor(0.0497, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "Epoch 500, Loss: 0.021005505695939064\n",
      "Epoch 1000, Loss: 0.02726524882018566\n",
      "Epoch 1500, Loss: 0.02233339101076126\n",
      "Epoch 2000, Loss: 0.023271430283784866\n",
      "Epoch 2500, Loss: 0.020427506417036057\n",
      "Epoch 3000, Loss: 0.019482135772705078\n",
      "Epoch 3500, Loss: 0.021276216953992844\n",
      "Epoch 4000, Loss: 0.019847702234983444\n",
      "Epoch 4500, Loss: 0.02162512019276619\n",
      "Epoch 5000, Loss: 0.016871077939867973\n",
      "Epoch 5500, Loss: 0.023722823709249496\n",
      "Epoch 6000, Loss: 0.02328241616487503\n",
      "Epoch 6500, Loss: 0.02313949540257454\n",
      "Epoch 7000, Loss: 0.02133345976471901\n",
      "Epoch 7500, Loss: 0.018636606633663177\n",
      "Epoch 8000, Loss: 0.019466567784547806\n",
      "Epoch 8500, Loss: 0.02233874425292015\n",
      "Epoch 9000, Loss: 0.018300209194421768\n",
      "Epoch 9500, Loss: 0.0226898193359375\n",
      "Epoch 9999, Loss: 0.017605293542146683\n",
      "0.03481607884168625\n"
     ]
    }
   ],
   "source": [
    "model_Gauss = PINN(layers).to(device)\n",
    "optimizer = optim.Adam(model_Gauss.parameters(), lr=1e-3)\n",
    "thresh_base, base_scores = train_GP_res(model_Gauss, optimizer, N_f,x_f, t_f, x_val, t_val, x_bc, t_bc, u_bc, epochs=epochs, threshold=threshold)\n",
    "print(val_loss(model_Gauss, x_val, t_val, x_bc, t_bc, u_bc).item())\n",
    "del model_Gauss, optimizer\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
